// Prevents additional console window on Windows in release, DO NOT REMOVE!!
#![cfg_attr(not(debug_assertions), windows_subsystem = "windows")]

// Import modules
mod data_models;
mod fs_manager;
mod llm_api;
mod prompts;
mod capture;

use arboard::Clipboard;
use base64::{engine::general_purpose, Engine as _};
use data_models::{Config, HistoryItem};
use llm_api::{ApiClient, LlmClient};
use screenshots::Screen;
use tauri::{AppHandle, Manager, GlobalShortcutManager};
use serde::Serialize;
#[cfg(debug_assertions)]
use serde_json::json;
use uuid::Uuid;
use std::sync::{Arc, Mutex, OnceLock};
use std::time::SystemTime;

// --- Tauri Commands ---

// æ—§çš„æç¤ºè¯æ„å»ºå‡½æ•°å·²ç§»è‡³ prompts.rs æ¨¡å—

fn default_title_for_lang(language: &str) -> String {
    if language == "zh-CN" { "æœªå‘½åå…¬å¼".to_string() } else { "Untitled formula".to_string() }
}

fn default_summary_for_lang(language: &str) -> String {
    if language == "zh-CN" { "åˆ†ææš‚ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚".to_string() } else { "Analysis is temporarily unavailable. Please try again.".to_string() }
}

#[derive(Serialize, Clone)]
struct RecognitionProgressPayload {
    id: String,
    stage: String, // "latex" | "analysis" | "confidence"
    latex: Option<String>,
    title: Option<String>,
    analysis: Option<data_models::Analysis>,
    confidence_score: Option<u8>,
    created_at: Option<String>,
    original_image: Option<String>,
    model_name: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    verification: Option<data_models::Verification>,
    #[serde(skip_serializing_if = "Option::is_none")]
    prompt_version: Option<String>, // "default" | "custom" | "full"
    #[serde(skip_serializing_if = "Option::is_none")]
    verification_report: Option<String>,
}

fn emit_progress(app_handle: &AppHandle, payload: RecognitionProgressPayload) {
    let _ = app_handle.emit_all("recognition_progress", payload);
}

fn compute_verification_result_from_struct(
    verification: &data_models::Verification,
) -> data_models::VerificationResult {
    // ä¾æ® coverage è®¡ç®—åˆ†æ•°ï¼›è‹¥æ—  coverageï¼Œåˆ™æŒ‰ status ä¸ issues æ•°é‡ä¼°ç®—
    let score: u8 = if let Some(cov) = &verification.coverage {
        let symbols_score = if cov.symbols_total > 0 {
            (100.0 * (cov.symbols_matched as f32) / (cov.symbols_total as f32)).round()
        } else {
            100.0
        };
        let terms_score = if cov.terms_total > 0 {
            (100.0 * (cov.terms_matched as f32) / (cov.terms_total as f32)).round()
        } else {
            100.0
        };
        let combined = (0.75 * symbols_score + 0.25 * terms_score).round();
        combined.clamp(0.0, 100.0) as u8
    } else {
        // æ— è¦†ç›–ç‡æ—¶çš„å¯å‘å¼
        let issues_len = verification.issues.len() as u32;
        match verification.status.as_str() {
            "ok" => 100,
            "warning" => 80u8.saturating_sub((issues_len * 2).min(20) as u8),
            _ => 60u8.saturating_sub((issues_len * 5).min(50) as u8),
        }
    };

    // ç”Ÿæˆç®€è¦æŠ¥å‘Š
    let report = if verification.status == "ok" && verification.issues.is_empty() {
        "LaTeX å®Œå…¨åŒ¹é…åŸå§‹å…¬å¼ã€‚".to_string()
    } else {
        // æ‹¼æ¥å‰è‹¥å¹²æ¡é—®é¢˜ï¼Œé¿å…è¿‡é•¿
        let mut lines: Vec<String> = Vec::new();
        for (i, issue) in verification.issues.iter().enumerate() {
            if i >= 10 { break; }
            lines.push(format!("- [{}] {}", issue.category, issue.message));
        }
        if verification.issues.len() > 10 {
            lines.push(format!("(å…¶ä½™ {} æ¡é—®é¢˜å·²çœç•¥)", verification.issues.len() - 10));
        }
        if lines.is_empty() {
            // æ— æ˜¾å¼é—®é¢˜ä½†çŠ¶æ€é ok
            match verification.status.as_str() {
                "warning" => "å­˜åœ¨ç‰ˆå¼/æ’ç‰ˆå·®å¼‚ï¼Œä½†ä¸å½±å“æ•°å­¦å«ä¹‰ã€‚".to_string(),
                _ => "å­˜åœ¨ä¸åŸå›¾ä¸ä¸€è‡´çš„å†…å®¹ï¼Œè¯·æ£€æŸ¥ç¬¦å·ã€ä¸Šä¸‹æ ‡ä¸é¡¹æ˜¯å¦åŒ¹é…ã€‚".to_string(),
            }
        } else {
            format!("å‘ç°ä»¥ä¸‹å·®å¼‚ï¼š\n{}", lines.join("\n"))
        }
    };

    data_models::VerificationResult { confidence_score: score, verification_report: report }
}

fn determine_prompt_version(config: &crate::data_models::Config) -> String {
    // æ£€æŸ¥å®é™…ä½¿ç”¨çš„æç¤ºè¯ç±»å‹
    // æ ¹æ®ä»£ç é€»è¾‘ï¼šå¦‚æœlatex_promptä¸ä¸ºç©ºï¼Œä½¿ç”¨åç«¯é»˜è®¤æç¤ºè¯ï¼›å¦åˆ™ä½¿ç”¨custom_prompt

    // å¦‚æœlatex_promptä¸ä¸ºç©ºï¼Œè¯´æ˜ä½¿ç”¨çš„æ˜¯åç«¯é»˜è®¤æç¤ºè¯ï¼ˆå«è¯­è¨€çº¦æŸçš„å®Œæ•´ç‰ˆï¼‰
    if !config.latex_prompt.is_empty() {
        return "full".to_string();
    }

    // å¦‚æœlatex_promptä¸ºç©ºä½†custom_promptä¸ä¸ºç©ºï¼Œè¯´æ˜ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯
    if !config.custom_prompt.is_empty() {
        return "custom".to_string();
    }

    // å…œåº•æƒ…å†µ
    "default".to_string()
}

#[tauri::command]
async fn test_connection(app_handle: AppHandle) -> Result<String, String> {
    // æ¯æ¬¡è¯»å–æœ€æ–°é…ç½®ï¼Œé¿å…æ—§é…ç½®ç¼“å­˜
    let config = fs_manager::read_config(&app_handle).map_err(|e| e.to_string())?;
    let client = ApiClient::new(config.to_llm_config());
    client
        .generate_content("ping")
        .await
        .map(|_| "ok".to_string())
        .map_err(|e| e.to_string())
}

#[tauri::command]
fn open_config_dir(app_handle: AppHandle) -> Result<(), String> {
    let dir = app_handle
        .path_resolver()
        .app_data_dir()
        .ok_or_else(|| "Failed to resolve app data dir".to_string())?;

    #[cfg(target_os = "windows")]
    {
        std::process::Command::new("explorer")
            .arg(dir)
            .spawn()
            .map_err(|e| e.to_string())?;
    }

    #[cfg(target_os = "macos")]
    {
        std::process::Command::new("open")
            .arg(dir)
            .spawn()
            .map_err(|e| e.to_string())?;
    }

    #[cfg(target_os = "linux")]
    {
        std::process::Command::new("xdg-open")
            .arg(dir)
            .spawn()
            .map_err(|e| e.to_string())?;
    }

    Ok(())
}

#[derive(Serialize)]
struct DefaultPromptsResponse {
    latex_prompt: String,
    analysis_prompt: String,
    verification_prompt: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    latex_language: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    analysis_language: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    verification_language: Option<String>,
}

#[tauri::command]
fn get_default_prompts() -> DefaultPromptsResponse {
    let (latex_prompt, analysis_prompt, verification_prompt) = prompts::get_base_prompts_tuple();
    // é»˜è®¤ä¸å«è¯­è¨€çº¦æŸï¼Œä½†ä¸ºç»Ÿä¸€å‰ç«¯â€œå†åŠ å·¥â€æ¥å£ä¹Ÿè¿”å›ç©º Option
    DefaultPromptsResponse { latex_prompt, analysis_prompt, verification_prompt, latex_language: None, analysis_language: None, verification_language: None }
}

#[derive(Serialize)]
struct FullPromptsResponse {
    latex_prompt: String,
    analysis_prompt: String,
    verification_prompt: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    latex_language: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    analysis_language: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    verification_language: Option<String>,
}

#[tauri::command]
fn get_full_prompts_with_language(language: String) -> FullPromptsResponse {
    // ç°åœ¨ï¼šLaTeX åªè¿”å›åŸºç¡€æç¤ºè¯ï¼ˆä¸å«è¯­è¨€çº¦æŸï¼‰ï¼ŒAnalysis/Verification è¿”å›â€œåŸºç¡€+è¯­è¨€â€
    let (latex_base, analysis_base, verification_base) = prompts::get_base_prompts_tuple();
    let analysis_language = Some(prompts::PromptManager::get_language_constraint_for(prompts::PromptType::Analysis, &language));
    let verification_language = Some(prompts::PromptManager::get_language_constraint_for(prompts::PromptType::Verification, &language));
    let analysis_prompt = format!("{}\n\n{}", analysis_base, analysis_language.clone().unwrap());
    let verification_prompt = format!("{}\n\n{}", verification_base, verification_language.clone().unwrap());
    FullPromptsResponse { latex_prompt: latex_base, analysis_prompt, verification_prompt, latex_language: None, analysis_language, verification_language }
}

#[derive(Serialize)]
struct PromptParts {
    base: String,
    #[serde(skip_serializing_if = "Option::is_none")]
    format_rule: Option<String>,
    language: String,
    full: String,
}

#[derive(Serialize)]
struct PromptPartsResponse {
    latex: PromptParts,
    analysis: PromptParts,
    verification: PromptParts,
}

#[tauri::command]
fn get_prompt_parts(language: String, default_format: String) -> PromptPartsResponse {
    // LaTeX partsï¼ˆè¯­è¨€æ®µç§»é™¤ï¼Œä»…åŸºç¡€+æ ¼å¼è§„åˆ™ï¼‰
    let latex_base = prompts::PromptManager::get_base_prompt(prompts::PromptType::LaTeX);
    let latex_format = prompts::format_rule_for_latex(&default_format);
    let latex_full = format!("{}{}", latex_base, latex_format);

    // Analysis parts
    let analysis_base = prompts::PromptManager::get_base_prompt(prompts::PromptType::Analysis);
    let analysis_lang = prompts::PromptManager::get_language_constraint_for(prompts::PromptType::Analysis, &language);
    let analysis_full = format!("{}\n\n{}", analysis_base, analysis_lang);

    // Verification parts
    let verification_base = prompts::PromptManager::get_base_prompt(prompts::PromptType::Verification);
    let verification_lang = prompts::PromptManager::get_language_constraint_for(prompts::PromptType::Verification, &language);
    let verification_full = format!("{}\n\n{}", verification_base, verification_lang);

    PromptPartsResponse {
        latex: PromptParts { base: latex_base, format_rule: Some(latex_format), language: String::new(), full: latex_full },
        analysis: PromptParts { base: analysis_base, format_rule: None, language: analysis_lang, full: analysis_full },
        verification: PromptParts { base: verification_base, format_rule: None, language: verification_lang, full: verification_full },
    }
}

#[tauri::command]
async fn recognize_from_screenshot(
    app_handle: AppHandle,
) -> Result<HistoryItem, String> {
    let config = fs_manager::read_config(&app_handle).map_err(|e| e.to_string())?;

    let screens = Screen::all().map_err(|e| e.to_string())?;
    if let Some(screen) = screens.first() {
        let image = screen.capture().map_err(|e| e.to_string())?;
        let png_bytes = image
            .to_png(None)
            .map_err(|e| e.to_string())?;
        let base64_image = general_purpose::STANDARD.encode(&png_bytes);

        let id = Uuid::new_v4().to_string();
        let created_at = chrono::Utc::now().to_rfc3339();
        let model_name = Some(config.default_engine.clone());

        let client = std::sync::Arc::new(ApiClient::new(config.to_llm_config()));

        // è¿è¡ŒæœŸä»…ä½¿ç”¨ç”¨æˆ·åœ¨å‰ç«¯ä¿å­˜çš„æç¤ºè¯ï¼›è‹¥ä¸ºç©ºåˆ™ç›´æ¥æŠ¥é”™ï¼Œæç¤ºç”¨æˆ·å»è®¾ç½®é¡µæ¢å¤é»˜è®¤æˆ–ä¿å­˜
        if config.latex_prompt.trim().is_empty() {
            return Err("LaTeX æç¤ºè¯æœªè®¾ç½®ã€‚è¯·åœ¨è®¾ç½®ä¸­å¡«å†™æˆ–ç‚¹å‡»â€˜æ¢å¤é»˜è®¤æç¤ºè¯â€™åé‡è¯•ã€‚".to_string());
        }
        if config.analysis_prompt.trim().is_empty() {
            return Err("åˆ†ææç¤ºè¯æœªè®¾ç½®ã€‚è¯·åœ¨è®¾ç½®ä¸­å¡«å†™æˆ–ç‚¹å‡»â€˜æ¢å¤é»˜è®¤æç¤ºè¯â€™åé‡è¯•ã€‚".to_string());
        }
        if config.verification_prompt.trim().is_empty() {
            return Err("æ ¸æŸ¥æç¤ºè¯æœªè®¾ç½®ã€‚è¯·åœ¨è®¾ç½®ä¸­å¡«å†™æˆ–ç‚¹å‡»â€˜æ¢å¤é»˜è®¤æç¤ºè¯â€™åé‡è¯•ã€‚".to_string());
        }

        let latex_prompt = {
            let mut p = config.latex_prompt.clone();
            p.push_str(&prompts::format_rule_for_latex(&config.default_latex_format));
            p
        };
        let analysis_prompt = {
            let mut p = config.analysis_prompt.clone();
            let lang = prompts::PromptManager::get_language_constraint_for(prompts::PromptType::Analysis, &config.language);
            p.push_str(&format!("\n\n{}", lang));
            p
        };
        // ç¬¬1æ¬¡å’Œç¬¬2æ¬¡è°ƒç”¨åŒæ—¶å‘å‡ºï¼ˆéƒ½åªè¾“å…¥å›¾ç‰‡ï¼‰
        let latex_task = {
            let c = client.clone();
            let latex_prompt = latex_prompt.clone();
            let img = base64_image.clone();
            tokio::spawn(async move { c.extract_latex(&latex_prompt, &img).await })
        };

        let analysis_task = {
            let c = client.clone();
            let analysis_prompt = analysis_prompt.clone();
            let img = base64_image.clone();
            tokio::spawn(async move { c.generate_analysis(&analysis_prompt, &img).await })
        };

        // ç­‰å¾…ç¬¬1æ¬¡è°ƒç”¨ï¼ˆLaTeXè¯†åˆ«ï¼‰å®Œæˆ
        let latex = match latex_task.await {
            Ok(Ok(latex)) => latex,
            Ok(Err(e)) => return Err(e.to_string()),
            Err(e) => return Err(format!("LaTeX task failed: {}", e)),
        };
        // æ‰“å°ç¬¬1æ¬¡è¿”å›ï¼ˆLaTeX æå–ç»“æœï¼‰
        #[cfg(debug_assertions)]
        {
            let payload = json!({ "latex": &latex });
            eprintln!("[LLM][Result][latex][{}] {}", id, payload.to_string());
        }
        let prompt_version = determine_prompt_version(&config);
        emit_progress(&app_handle, RecognitionProgressPayload {
            id: id.clone(), stage: "latex".into(), latex: Some(latex.clone()),
            title: None, analysis: None, confidence_score: None,
            created_at: Some(created_at.clone()),
            original_image: Some(format!("data:image/png;base64,{}", base64_image.clone())),
            model_name: model_name.clone(),
            verification: None,
            prompt_version: Some(prompt_version.clone()),
            verification_report: None,
        });

        // ç¬¬3é˜¶æ®µï¼šä»…ä½¿ç”¨ç”¨æˆ·ä¿å­˜çš„æ ¸æŸ¥æç¤ºè¯ï¼ˆå›¾åƒ+LaTeXï¼‰è®¡ç®—ç½®ä¿¡åº¦ä¸æŠ¥å‘Š
        let verification_prompt = {
            let mut p = config.verification_prompt.clone();
            let lang = prompts::PromptManager::get_language_constraint_for(prompts::PromptType::Verification, &config.language);
            p.push_str(&format!("\n\n{}", lang));
            p
        };
        let verification_task = {
            let c = client.clone();
            let latex = latex.clone();
            let img = base64_image.clone();
            let verification_prompt = verification_prompt.clone();
            tokio::spawn(async move {
                let vr = c.get_verification_result_with_image(&verification_prompt, &latex, &img)
                    .await
                    .unwrap_or(crate::data_models::VerificationResult { confidence_score: 0, verification_report: "éªŒè¯å¤±è´¥".to_string() });
                (vr, None)
            })
        };

        // ç­‰å¾…ç¬¬2æ¬¡è°ƒç”¨ï¼ˆåˆ†æï¼‰ç»“æœ
        let (title, analysis) = match analysis_task.await {
            Ok(Ok(v)) => v,
            _ => (
                default_title_for_lang(&config.language),
                crate::data_models::Analysis { summary: default_summary_for_lang(&config.language), variables: Vec::new(), terms: Vec::new(), suggestions: Vec::new() }
            )
        };
        // æ‰“å°ç¬¬2æ¬¡è¿”å›ï¼ˆåˆ†æï¼šæ ‡é¢˜/ç®€ä»‹/å˜é‡/é¡¹/å»ºè®®ï¼‰
        #[cfg(debug_assertions)]
        {
            let payload = json!({ "title": &title, "analysis": &analysis });
            eprintln!("[LLM][Result][analysis][{}] {}", id, payload.to_string());
        }
        emit_progress(&app_handle, RecognitionProgressPayload {
            id: id.clone(), stage: "analysis".into(), latex: None,
            title: Some(title.clone()), analysis: Some(analysis.clone()), confidence_score: None,
            created_at: None, original_image: None, model_name: model_name.clone(),
            verification: None,
            prompt_version: Some(prompt_version.clone()),
            verification_report: None,
        });

        // ç­‰å¾…ç¬¬3æ¬¡è°ƒç”¨ï¼ˆéªŒè¯ï¼‰ç»“æœ
        let (verification_result, verification) = match verification_task.await {
            Ok(result) => result,
            Err(e) => {
                eprintln!("Verification task failed: {}", e);
                (crate::data_models::VerificationResult {
                    confidence_score: 0,
                    verification_report: "éªŒè¯å¤±è´¥".to_string(),
                }, None)
            }
        };
        // æ‰“å°ç¬¬3æ¬¡è¿”å›ï¼ˆç½®ä¿¡åº¦ + æ ¸æŸ¥ï¼‰
        #[cfg(debug_assertions)]
        {
            let payload = json!({ "confidence_score": verification_result.confidence_score, "verification_report": &verification_result.verification_report, "verification": &verification });
            eprintln!("[LLM][Result][confidence+verify][{}] {}", id, payload.to_string());
        }
        emit_progress(&app_handle, RecognitionProgressPayload {
            id: id.clone(), stage: "confidence".into(), latex: None,
            title: None, analysis: None, confidence_score: Some(verification_result.confidence_score),
            created_at: None, original_image: None, model_name: model_name.clone(),
            verification: verification.clone(),
            prompt_version: Some(prompt_version.clone()),
            verification_report: Some(verification_result.verification_report.clone()),
        });

        let mut history_item = HistoryItem {
            id: id.clone(),
            latex,
            title,
            analysis,
            is_favorite: false,
            created_at: created_at.clone(),
            confidence_score: verification_result.confidence_score,
            original_image: base64_image.to_string(),
            model_name: model_name.clone(),
            verification,
            verification_report: Some(verification_result.verification_report),
        };

        // å°†å›¾ç‰‡ä¿å­˜ä¸ºæ–‡ä»¶ï¼ˆæ—¥æœŸå‰ç¼€ï¼‰ï¼Œå¹¶ç”¨æ–‡ä»¶è·¯å¾„æ›¿æ¢åŸå§‹å›¾ç‰‡å­—æ®µ
        let date_str = chrono::DateTime::parse_from_rfc3339(&history_item.created_at)
            .map(|dt| dt.format("%Y%m%d_%H%M%S").to_string())
            .unwrap_or_else(|_| chrono::Utc::now().format("%Y%m%d_%H%M%S").to_string());
        let stem = format!("{}_{}", date_str, history_item.id);
        let img_path = fs_manager::save_png_to_pictures(&app_handle, &stem, &png_bytes)
            .map_err(|e| e.to_string())?;
        history_item.original_image = img_path.to_string_lossy().to_string();

        // æŒä¹…åŒ–ä¿å­˜å†å²ï¼Œé˜²æ­¢å‰ç«¯é¡µé¢åˆ‡æ¢å¯¼è‡´ç»“æœä¸¢å¤±
        let mut history = fs_manager::read_history(&app_handle).map_err(|e| e.to_string())?;
        history.insert(0, history_item.clone());
        fs_manager::write_history(&app_handle, &history).map_err(|e| e.to_string())?;

        Ok(history_item)
    } else {
        Err("No screens found.".to_string())
    }
}

#[tauri::command]
async fn recognize_from_file(
    app_handle: AppHandle,
    file_path: String,
) -> Result<HistoryItem, String> {
    #[cfg(debug_assertions)]
    {
        eprintln!("ğŸ”¥ [DEBUG] recognize_from_file called with: {}", file_path);
        eprintln!("ğŸ”¥ [DEBUG] This function should only be called once per recognition");
    }

    let config = fs_manager::read_config(&app_handle).map_err(|e| e.to_string())?;
    let image_data = std::fs::read(&file_path).map_err(|e| e.to_string())?;
    // ç»Ÿä¸€è½¬æ¢ä¸º PNG å­—èŠ‚
    let dyn_img = image::load_from_memory(&image_data).map_err(|e| e.to_string())?;
    let mut png_bytes: Vec<u8> = Vec::new();
    {
        let mut cursor = std::io::Cursor::new(&mut png_bytes);
        dyn_img
            .write_to(&mut cursor, image::ImageFormat::Png)
            .map_err(|e| e.to_string())?;
    }
    let base64_image = general_purpose::STANDARD.encode(&png_bytes);

    let id = Uuid::new_v4().to_string();
    let created_at = chrono::Utc::now().to_rfc3339();
    let model_name = Some(config.default_engine.clone());

        let client = std::sync::Arc::new(ApiClient::new(config.to_llm_config()));

    if config.latex_prompt.trim().is_empty() {
        return Err("LaTeX æç¤ºè¯æœªè®¾ç½®ã€‚è¯·åœ¨è®¾ç½®ä¸­å¡«å†™æˆ–ç‚¹å‡»â€˜æ¢å¤é»˜è®¤æç¤ºè¯â€™åé‡è¯•ã€‚".to_string());
    }
    if config.analysis_prompt.trim().is_empty() {
        return Err("åˆ†ææç¤ºè¯æœªè®¾ç½®ã€‚è¯·åœ¨è®¾ç½®ä¸­å¡«å†™æˆ–ç‚¹å‡»â€˜æ¢å¤é»˜è®¤æç¤ºè¯â€™åé‡è¯•ã€‚".to_string());
    }
    if config.verification_prompt.trim().is_empty() {
        return Err("æ ¸æŸ¥æç¤ºè¯æœªè®¾ç½®ã€‚è¯·åœ¨è®¾ç½®ä¸­å¡«å†™æˆ–ç‚¹å‡»â€˜æ¢å¤é»˜è®¤æç¤ºè¯â€™åé‡è¯•ã€‚".to_string());
    }
    let latex_prompt = {
        let mut p = config.latex_prompt.clone();
        p.push_str(&prompts::format_rule_for_latex(&config.default_latex_format));
        p
    };
        let analysis_prompt = {
            let mut p = config.analysis_prompt.clone();
            let lang = prompts::PromptManager::get_language_constraint_for(prompts::PromptType::Analysis, &config.language);
            p.push_str(&format!("\n\n{}", lang));
            p
        };
    // ç¬¬1æ¬¡å’Œç¬¬2æ¬¡è°ƒç”¨åŒæ—¶å‘å‡ºï¼ˆéƒ½åªè¾“å…¥å›¾ç‰‡ï¼‰
    let latex_task = {
        let c = client.clone();
        let latex_prompt = latex_prompt.clone();
        let img = base64_image.clone();
        tokio::spawn(async move { c.extract_latex(&latex_prompt, &img).await })
    };

    let analysis_task = {
        let c = client.clone();
        let analysis_prompt = analysis_prompt.clone();
        let img = base64_image.clone();
        tokio::spawn(async move { c.generate_analysis(&analysis_prompt, &img).await })
    };

    // ç­‰å¾…ç¬¬1æ¬¡è°ƒç”¨ï¼ˆLaTeXè¯†åˆ«ï¼‰å®Œæˆ
    let latex = match latex_task.await {
        Ok(Ok(latex)) => latex,
        Ok(Err(e)) => return Err(e.to_string()),
        Err(e) => return Err(format!("LaTeX task failed: {}", e)),
    };
    #[cfg(debug_assertions)]
    {
        let payload = json!({ "latex": &latex });
        eprintln!("[LLM][Result][latex][{}] {}", id, payload.to_string());
    }
    let prompt_version = determine_prompt_version(&config);
    emit_progress(&app_handle, RecognitionProgressPayload { id: id.clone(), stage: "latex".into(), latex: Some(latex.clone()), title: None, analysis: None, confidence_score: None, created_at: Some(created_at.clone()), original_image: Some(format!("data:image/png;base64,{}", base64_image.clone())), model_name: model_name.clone(), verification: None, prompt_version: Some(prompt_version.clone()), verification_report: None });

    // ç¬¬3æ¬¡è°ƒç”¨ï¼šåœ¨ç¬¬1æ¬¡å®Œæˆåå‘å‡ºï¼ˆè¾“å…¥å›¾ç‰‡+LaTeXï¼‰
    let verification_prompt = {
        let mut p = config.verification_prompt.clone();
        let lang = prompts::PromptManager::get_language_constraint_for(prompts::PromptType::Verification, &config.language);
        p.push_str(&format!("\n\n{}", lang));
        p
    };
    let verification_task = {
        let c = client.clone();
        let latex = latex.clone();
        let img = base64_image.clone();
            let verification_prompt = verification_prompt.clone();
        tokio::spawn(async move {
                let vr = c.get_verification_result_with_image(&verification_prompt, &latex, &img)
                    .await
                    .unwrap_or(crate::data_models::VerificationResult { confidence_score: 0, verification_report: "éªŒè¯å¤±è´¥".to_string() });
                (vr, None)
        })
    };
    // ç­‰å¾…ç¬¬2æ¬¡è°ƒç”¨ï¼ˆåˆ†æï¼‰ç»“æœ
    let (title, analysis) = match analysis_task.await { Ok(Ok(v)) => v, _ => (default_title_for_lang(&config.language), crate::data_models::Analysis { summary: default_summary_for_lang(&config.language), variables: Vec::new(), terms: Vec::new(), suggestions: Vec::new() }) };
    #[cfg(debug_assertions)]
    {
        let payload = json!({ "title": &title, "analysis": &analysis });
        eprintln!("[LLM][Result][analysis][{}] {}", id, payload.to_string());
    }
    emit_progress(&app_handle, RecognitionProgressPayload { id: id.clone(), stage: "analysis".into(), latex: None, title: Some(title.clone()), analysis: Some(analysis.clone()), confidence_score: None, created_at: None, original_image: None, model_name: model_name.clone(), verification: None, prompt_version: Some(prompt_version.clone()), verification_report: None });

    // ç­‰å¾…ç¬¬3æ¬¡è°ƒç”¨ï¼ˆéªŒè¯ï¼‰ç»“æœ
    let (verification_result, verification) = match verification_task.await {
        Ok(result) => result,
        Err(e) => {
            eprintln!("Verification task failed: {}", e);
            (crate::data_models::VerificationResult {
                confidence_score: 0,
                verification_report: "éªŒè¯å¤±è´¥".to_string(),
            }, None)
        }
    };
    // è‹¥æœ‰ç»†ç²’åº¦æ ¸æŸ¥ï¼Œåˆ™ä»¥å…¶è®¡ç®—çš„åˆ†æ•°/æŠ¥å‘Šä¸ºå‡†ï¼Œå¦åˆ™ä½¿ç”¨å›é€€è¯„åˆ†
        let final_verification_result = verification_result.clone();
    #[cfg(debug_assertions)]
    {
        let payload = json!({ "confidence_score": final_verification_result.confidence_score, "verification_report": &final_verification_result.verification_report, "verification": &verification });
        eprintln!("[LLM][Result][confidence+verify][{}] {}", id, payload.to_string());
    }
    emit_progress(&app_handle, RecognitionProgressPayload { id: id.clone(), stage: "confidence".into(), latex: None, title: None, analysis: None, confidence_score: Some(final_verification_result.confidence_score), created_at: None, original_image: None, model_name: model_name.clone(), verification: verification.clone(), prompt_version: Some(prompt_version.clone()), verification_report: Some(final_verification_result.verification_report.clone()) });

    let mut history_item = HistoryItem {
        id: id.clone(),
        latex,
        title,
        analysis,
        is_favorite: false,
        created_at: created_at.clone(),
        confidence_score: final_verification_result.confidence_score,
        original_image: base64_image.to_string(),
        model_name: model_name.clone(),
            verification: None,
        verification_report: Some(final_verification_result.verification_report),
    };

    // å°†å›¾ç‰‡ä¿å­˜ä¸ºæ–‡ä»¶ï¼ˆæ—¥æœŸå‰ç¼€ï¼‰ï¼Œå¹¶ç”¨æ–‡ä»¶è·¯å¾„æ›¿æ¢åŸå§‹å›¾ç‰‡å­—æ®µ
    let date_str = chrono::DateTime::parse_from_rfc3339(&history_item.created_at)
        .map(|dt| dt.format("%Y%m%d_%H%M%S").to_string())
        .unwrap_or_else(|_| chrono::Utc::now().format("%Y%m%d_%H%M%S").to_string());
    let stem = format!("{}_{}", date_str, history_item.id);
    let img_path = fs_manager::save_png_to_pictures(&app_handle, &stem, &png_bytes)
        .map_err(|e| e.to_string())?;
    history_item.original_image = img_path.to_string_lossy().to_string();

    // æŒä¹…åŒ–ä¿å­˜å†å²
    let mut history = fs_manager::read_history(&app_handle).map_err(|e| e.to_string())?;
    history.insert(0, history_item.clone());
    fs_manager::write_history(&app_handle, &history).map_err(|e| e.to_string())?;

    Ok(history_item)
}

#[tauri::command]
async fn recognize_from_clipboard(
    app_handle: AppHandle,
) -> Result<HistoryItem, String> {
    let config = fs_manager::read_config(&app_handle).map_err(|e| e.to_string())?;
    let mut clipboard = Clipboard::new().map_err(|e| e.to_string())?;

    let image = clipboard.get_image().map_err(|e| e.to_string())?;
    
    // Convert Arboard's image data to a dynamic image
    let img_buffer = image::ImageBuffer::from_raw(
        image.width as u32,
        image.height as u32,
        image.bytes.into_owned(),
    )
    .ok_or("Failed to create image buffer from clipboard data")?;
    
    let dynamic_img = image::DynamicImage::ImageRgba8(img_buffer);

    // Encode to PNG and then to base64
    let mut png_bytes = Vec::new();
    let mut cursor = std::io::Cursor::new(&mut png_bytes);
    dynamic_img
        .write_to(&mut cursor, image::ImageFormat::Png)
        .map_err(|e| format!("Failed to encode clipboard image: {}", e))?;
    let base64_image = general_purpose::STANDARD.encode(&png_bytes);

    let id = Uuid::new_v4().to_string();
    let created_at = chrono::Utc::now().to_rfc3339();
    let model_name = Some(config.default_engine.clone());

    let client = std::sync::Arc::new(ApiClient::new(config.to_llm_config()));

    if config.latex_prompt.trim().is_empty() {
        return Err("LaTeX æç¤ºè¯æœªè®¾ç½®ã€‚è¯·åœ¨è®¾ç½®ä¸­å¡«å†™æˆ–ç‚¹å‡»â€˜æ¢å¤é»˜è®¤æç¤ºè¯â€™åé‡è¯•ã€‚".to_string());
    }
    if config.analysis_prompt.trim().is_empty() {
        return Err("åˆ†ææç¤ºè¯æœªè®¾ç½®ã€‚è¯·åœ¨è®¾ç½®ä¸­å¡«å†™æˆ–ç‚¹å‡»â€˜æ¢å¤é»˜è®¤æç¤ºè¯â€™åé‡è¯•ã€‚".to_string());
    }
    if config.verification_prompt.trim().is_empty() {
        return Err("æ ¸æŸ¥æç¤ºè¯æœªè®¾ç½®ã€‚è¯·åœ¨è®¾ç½®ä¸­å¡«å†™æˆ–ç‚¹å‡»â€˜æ¢å¤é»˜è®¤æç¤ºè¯â€™åé‡è¯•ã€‚".to_string());
    }
    let latex_prompt = {
        let mut p = config.latex_prompt.clone();
        p.push_str(&prompts::format_rule_for_latex(&config.default_latex_format));
        p
    };
    let analysis_prompt = {
        let mut p = config.analysis_prompt.clone();
        let lang = prompts::PromptManager::get_language_constraint_for(prompts::PromptType::Analysis, &config.language);
        p.push_str(&format!("\n\n{}", lang));
        p
    };
    // ç¬¬1æ¬¡å’Œç¬¬2æ¬¡è°ƒç”¨åŒæ—¶å‘å‡ºï¼ˆéƒ½åªè¾“å…¥å›¾ç‰‡ï¼‰
    let latex_task = {
        let c = client.clone();
        let latex_prompt = latex_prompt.clone();
        let img = base64_image.clone();
        tokio::spawn(async move { c.extract_latex(&latex_prompt, &img).await })
    };

    let analysis_task = {
        let c = client.clone();
        let analysis_prompt = analysis_prompt.clone();
        let img = base64_image.clone();
        tokio::spawn(async move { c.generate_analysis(&analysis_prompt, &img).await })
    };

    // ç­‰å¾…ç¬¬1æ¬¡è°ƒç”¨ï¼ˆLaTeXè¯†åˆ«ï¼‰å®Œæˆ
    let latex = match latex_task.await {
        Ok(Ok(latex)) => latex,
        Ok(Err(e)) => return Err(e.to_string()),
        Err(e) => return Err(format!("LaTeX task failed: {}", e)),
    };
    let prompt_version = determine_prompt_version(&config);
    emit_progress(&app_handle, RecognitionProgressPayload { id: id.clone(), stage: "latex".into(), latex: Some(latex.clone()), title: None, analysis: None, confidence_score: None, created_at: Some(created_at.clone()), original_image: Some(format!("data:image/png;base64,{}", base64_image.clone())), model_name: model_name.clone(), verification: None, prompt_version: Some(prompt_version.clone()), verification_report: None });

    // ç¬¬3æ¬¡è°ƒç”¨ï¼šåœ¨ç¬¬1æ¬¡å®Œæˆåå‘å‡ºï¼ˆè¾“å…¥å›¾ç‰‡+LaTeXï¼‰
    let verification_prompt = config.verification_prompt.clone();
    let verification_task = {
        let c = client.clone();
        let latex = latex.clone();
        let img = base64_image.clone();
            let verification_prompt = verification_prompt.clone();
        tokio::spawn(async move {
                let vr = c.get_verification_result_with_image(&verification_prompt, &latex, &img)
                    .await
                    .unwrap_or(crate::data_models::VerificationResult { confidence_score: 0, verification_report: "éªŒè¯å¤±è´¥".to_string() });
                (vr, None)
        })
    };

    // ç­‰å¾…ç¬¬2æ¬¡è°ƒç”¨ï¼ˆåˆ†æï¼‰ç»“æœ
    let (title, analysis) = match analysis_task.await { Ok(Ok(v)) => v, _ => (default_title_for_lang(&config.language), crate::data_models::Analysis { summary: default_summary_for_lang(&config.language), variables: Vec::new(), terms: Vec::new(), suggestions: Vec::new() }) };
    emit_progress(&app_handle, RecognitionProgressPayload { id: id.clone(), stage: "analysis".into(), latex: None, title: Some(title.clone()), analysis: Some(analysis.clone()), confidence_score: None, created_at: None, original_image: None, model_name: model_name.clone(), verification: None, prompt_version: Some(prompt_version.clone()), verification_report: None });

    // ç­‰å¾…ç¬¬3æ¬¡è°ƒç”¨ï¼ˆéªŒè¯ï¼‰ç»“æœ
    let (verification_result, verification) = match verification_task.await {
        Ok(result) => result,
        Err(e) => {
            eprintln!("Verification task failed: {}", e);
            (crate::data_models::VerificationResult {
                confidence_score: 0,
                verification_report: "éªŒè¯å¤±è´¥".to_string(),
            }, None)
        }
    };
    emit_progress(&app_handle, RecognitionProgressPayload { id: id.clone(), stage: "confidence".into(), latex: None, title: None, analysis: None, confidence_score: Some(verification_result.confidence_score), created_at: None, original_image: None, model_name: model_name.clone(), verification: verification.clone(), prompt_version: Some(prompt_version.clone()), verification_report: Some(verification_result.verification_report.clone()) });

    let mut history_item = HistoryItem {
        id: id.clone(),
        latex,
        title,
        analysis,
        is_favorite: false,
        created_at: created_at.clone(),
        confidence_score: verification_result.confidence_score,
        original_image: base64_image.to_string(),
        model_name: model_name.clone(),
        verification,
        verification_report: Some(verification_result.verification_report),
    };

    // å°†å›¾ç‰‡ä¿å­˜ä¸ºæ–‡ä»¶ï¼ˆæ—¥æœŸå‰ç¼€ï¼‰ï¼Œå¹¶ç”¨æ–‡ä»¶è·¯å¾„æ›¿æ¢åŸå§‹å›¾ç‰‡å­—æ®µ
    let date_str = chrono::DateTime::parse_from_rfc3339(&history_item.created_at)
        .map(|dt| dt.format("%Y%m%d_%H%M%S").to_string())
        .unwrap_or_else(|_| chrono::Utc::now().format("%Y%m%d_%H%M%S").to_string());
    let stem = format!("{}_{}", date_str, history_item.id);
    let img_path = fs_manager::save_png_to_pictures(&app_handle, &stem, &png_bytes)
        .map_err(|e| e.to_string())?;
    history_item.original_image = img_path.to_string_lossy().to_string();

    // æŒä¹…åŒ–ä¿å­˜å†å²
    let mut history = fs_manager::read_history(&app_handle).map_err(|e| e.to_string())?;
    history.insert(0, history_item.clone());
    fs_manager::write_history(&app_handle, &history).map_err(|e| e.to_string())?;

    Ok(history_item)
}

#[tauri::command]
async fn recognize_from_image_base64(
    app_handle: AppHandle,
    image_base64: String,
) -> Result<HistoryItem, String> {
    let config = fs_manager::read_config(&app_handle).map_err(|e| e.to_string())?;

    // è¾“å…¥å·²æ˜¯ base64 çš„ PNG æ•°æ®
    let base64_image = image_base64;
    let png_bytes = match base64::engine::general_purpose::STANDARD.decode(&base64_image) {
        Ok(bytes) => bytes,
        Err(e) => return Err(format!("Failed to decode base64 image: {}", e)),
    };

    let id = Uuid::new_v4().to_string();
    let created_at = chrono::Utc::now().to_rfc3339();
    let model_name = Some(config.default_engine.clone());

    let client = std::sync::Arc::new(ApiClient::new(config.to_llm_config()));

    let latex_prompt = if !config.latex_prompt.is_empty() {
        let mut p = config.latex_prompt.clone();
        p.push_str(&prompts::format_rule_for_latex(&config.default_latex_format));
        p
    } else {
        config.custom_prompt.clone()
    };
    let analysis_prompt = if !config.analysis_prompt.is_empty() {
        let mut p = config.analysis_prompt.clone();
        let lang = prompts::PromptManager::get_language_constraint_for(prompts::PromptType::Analysis, &config.language);
        p.push_str(&format!("\n\n{}", lang));
        p
    } else {
        config.custom_prompt.clone()
    };

    // ç¬¬1æ¬¡å’Œç¬¬2æ¬¡è°ƒç”¨åŒæ—¶å‘å‡ºï¼ˆéƒ½åªè¾“å…¥å›¾ç‰‡ï¼‰
    let latex_task = {
        let c = client.clone();
        let latex_prompt = latex_prompt.clone();
        let img = base64_image.clone();
        tokio::spawn(async move { c.extract_latex(&latex_prompt, &img).await })
    };

    let analysis_task = {
        let c = client.clone();
        let analysis_prompt = analysis_prompt.clone();
        let img = base64_image.clone();
        tokio::spawn(async move { c.generate_analysis(&analysis_prompt, &img).await })
    };

    // ç­‰å¾…ç¬¬1æ¬¡è°ƒç”¨ï¼ˆLaTeXè¯†åˆ«ï¼‰å®Œæˆ
    let latex = match latex_task.await {
        Ok(Ok(latex)) => latex,
        Ok(Err(e)) => return Err(e.to_string()),
        Err(e) => return Err(format!("LaTeX task failed: {}", e)),
    };
    let prompt_version = determine_prompt_version(&config);
    emit_progress(&app_handle, RecognitionProgressPayload { id: id.clone(), stage: "latex".into(), latex: Some(latex.clone()), title: None, analysis: None, confidence_score: None, created_at: Some(created_at.clone()), original_image: Some(format!("data:image/png;base64,{}", base64_image.clone())), model_name: model_name.clone(), verification: None, prompt_version: Some(prompt_version.clone()), verification_report: None });

    // ç¬¬3æ¬¡è°ƒç”¨ï¼šåœ¨ç¬¬1æ¬¡å®Œæˆåå‘å‡ºï¼ˆè¾“å…¥å›¾ç‰‡+LaTeXï¼‰ï¼Œä¼˜å…ˆç»†ç²’åº¦æ ¸æŸ¥
    let verification_prompt = {
        let mut p = config.verification_prompt.clone();
        let lang = prompts::PromptManager::get_language_constraint_for(prompts::PromptType::Verification, &config.language);
        p.push_str(&format!("\n\n{}", lang));
        p
    };
    let verification_task = {
        let c = client.clone();
        let latex = latex.clone();
        let img = base64_image.clone();
            let verification_prompt = verification_prompt.clone();
        tokio::spawn(async move {
                let vr = c.get_verification_result_with_image(&verification_prompt, &latex, &img)
                    .await
                    .unwrap_or(crate::data_models::VerificationResult { confidence_score: 0, verification_report: "éªŒè¯å¤±è´¥".to_string() });
                (vr, None)
        })
    };

    // ç­‰å¾…ç¬¬2æ¬¡è°ƒç”¨ï¼ˆåˆ†æï¼‰ç»“æœ
    let (title, analysis) = match analysis_task.await {
        Ok(Ok(v)) => v,
        _ => (
            default_title_for_lang(&config.language),
            crate::data_models::Analysis { summary: default_summary_for_lang(&config.language), variables: Vec::new(), terms: Vec::new(), suggestions: Vec::new() }
        )
    };
    emit_progress(&app_handle, RecognitionProgressPayload { id: id.clone(), stage: "analysis".into(), latex: None, title: Some(title.clone()), analysis: Some(analysis.clone()), confidence_score: None, created_at: None, original_image: None, model_name: model_name.clone(), verification: None, prompt_version: Some(prompt_version.clone()), verification_report: None });

    // ç­‰å¾…ç¬¬3æ¬¡è°ƒç”¨ï¼ˆéªŒè¯ï¼‰ç»“æœ
    let (verification_result, verification) = match verification_task.await {
        Ok(result) => result,
        Err(e) => {
            eprintln!("Verification task failed: {}", e);
            (crate::data_models::VerificationResult {
                confidence_score: 0,
                verification_report: "éªŒè¯å¤±è´¥".to_string(),
            }, None)
        }
    };
    emit_progress(&app_handle, RecognitionProgressPayload { id: id.clone(), stage: "confidence".into(), latex: None, title: None, analysis: None, confidence_score: Some(verification_result.confidence_score), created_at: None, original_image: None, model_name: model_name.clone(), verification: verification.clone(), prompt_version: Some(prompt_version.clone()), verification_report: Some(verification_result.verification_report.clone()) });

    let mut history_item = HistoryItem {
        id: id.clone(),
        latex,
        title,
        analysis,
        is_favorite: false,
        created_at: created_at.clone(),
        confidence_score: verification_result.confidence_score,
        original_image: base64_image.to_string(),
        model_name: model_name.clone(),
        verification,
        verification_report: Some(verification_result.verification_report),
    };

    // å°†å›¾ç‰‡ä¿å­˜ä¸ºæ–‡ä»¶ï¼Œå¹¶æ›¿æ¢ä¸ºè·¯å¾„
    let date_str = chrono::DateTime::parse_from_rfc3339(&history_item.created_at)
        .map(|dt| dt.format("%Y%m%d_%H%M%S").to_string())
        .unwrap_or_else(|_| chrono::Utc::now().format("%Y%m%d_%H%M%S").to_string());
    let stem = format!("{}_{}", date_str, history_item.id);
    let img_path = fs_manager::save_png_to_pictures(&app_handle, &stem, &png_bytes)
        .map_err(|e| e.to_string())?;
    history_item.original_image = img_path.to_string_lossy().to_string();

    // æŒä¹…åŒ–ä¿å­˜å†å²
    let mut history = fs_manager::read_history(&app_handle).map_err(|e| e.to_string())?;
    history.insert(0, history_item.clone());
    fs_manager::write_history(&app_handle, &history).map_err(|e| e.to_string())?;

    Ok(history_item)
}
#[tauri::command]
fn copy_image_to_clipboard(image_path: String) -> Result<(), String> {
    // è¯»å–å›¾ç‰‡å¹¶å¤åˆ¶åˆ°ç³»ç»Ÿå‰ªè´´æ¿
    let bytes = std::fs::read(&image_path).map_err(|e| e.to_string())?;
    let dyn_img = image::load_from_memory(&bytes).map_err(|e| e.to_string())?;
    let rgba = dyn_img.to_rgba8();
    let (w, h) = rgba.dimensions();
    let img_data = arboard::ImageData {
        width: w as usize,
        height: h as usize,
        bytes: std::borrow::Cow::Owned(rgba.into_raw()),
    };
    let mut clipboard = Clipboard::new().map_err(|e| e.to_string())?;
    clipboard.set_image(img_data).map_err(|e| e.to_string())
}

#[tauri::command]
fn read_image_as_data_url(image_path: String) -> Result<String, String> {
    let bytes = std::fs::read(&image_path).map_err(|e| e.to_string())?;
    let mime = if image_path.to_ascii_lowercase().ends_with(".jpg")
        || image_path.to_ascii_lowercase().ends_with(".jpeg")
    {
        "image/jpeg"
    } else if image_path.to_ascii_lowercase().ends_with(".gif") {
        "image/gif"
    } else {
        // default to png
        "image/png"
    };
    let encoded = base64::engine::general_purpose::STANDARD.encode(bytes);
    Ok(format!("data:{};base64,{}", mime, encoded))
}

struct HistoryCacheState {
    last_mtime: Option<SystemTime>,
    data: Vec<HistoryItem>,
}

static HISTORY_CACHE: OnceLock<Arc<Mutex<HistoryCacheState>>> = OnceLock::new();

fn init_cache_if_needed() -> Arc<Mutex<HistoryCacheState>> {
    HISTORY_CACHE
        .get_or_init(|| {
            Arc::new(Mutex::new(HistoryCacheState {
                last_mtime: None,
                data: Vec::new(),
            }))
        })
        .clone()
}

#[tauri::command]
fn get_history(app_handle: AppHandle) -> Result<Vec<HistoryItem>, String> {
    let cache = init_cache_if_needed();
    let history_path = fs_manager::get_history_path(&app_handle).map_err(|e| e.to_string())?;
    let mtime = std::fs::metadata(&history_path)
        .and_then(|m| m.modified())
        .unwrap_or(SystemTime::UNIX_EPOCH);

    {
        let cache_guard = cache.lock().unwrap();
        if let Some(last) = cache_guard.last_mtime {
            if last == mtime {
                return Ok(cache_guard.data.clone());
            }
        }
    }

    let data = fs_manager::read_history(&app_handle).map_err(|e| e.to_string())?;
    {
        let mut cache_guard = cache.lock().unwrap();
        cache_guard.last_mtime = Some(mtime);
        cache_guard.data = data.clone();
    }
    Ok(data)
}

#[tauri::command]
fn save_to_history(app_handle: AppHandle, item: HistoryItem) -> Result<(), String> {
    let mut history = fs_manager::read_history(&app_handle).map_err(|e| e.to_string())?;
    history.insert(0, item);
    fs_manager::write_history(&app_handle, &history).map_err(|e| e.to_string())?;
    // æ›´æ–°ç¼“å­˜
    let cache = init_cache_if_needed();
    let mut cache_guard = cache.lock().unwrap();
    cache_guard.data = history;
    cache_guard.last_mtime = std::fs::metadata(
        &fs_manager::get_history_path(&app_handle).map_err(|e| e.to_string())?
    ).and_then(|m| m.modified()).ok();
    Ok(())
}

#[tauri::command]
fn delete_history_item(app_handle: AppHandle, id: String) -> Result<(), String> {
    let mut history = fs_manager::read_history(&app_handle).map_err(|e| e.to_string())?;
    let before_len = history.len();
    history.retain(|item| item.id != id);
    if history.len() == before_len {
        return Err(format!("Item with ID '{}' not found", id));
    }
    fs_manager::write_history(&app_handle, &history).map_err(|e| e.to_string())?;
    let cache = init_cache_if_needed();
    let mut cache_guard = cache.lock().unwrap();
    cache_guard.data = history;
    cache_guard.last_mtime = std::fs::metadata(
        &fs_manager::get_history_path(&app_handle).map_err(|e| e.to_string())?
    ).and_then(|m| m.modified()).ok();
    Ok(())
}

#[tauri::command]
fn update_history_title(
    app_handle: AppHandle,
    id: String,
    title: String,
) -> Result<(), String> {
    let mut history = fs_manager::read_history(&app_handle).map_err(|e| e.to_string())?;
    if let Some(item) = history.iter_mut().find(|item| item.id == id) {
        item.title = title;
        fs_manager::write_history(&app_handle, &history).map_err(|e| e.to_string())?;
        // æ›´æ–°ç¼“å­˜
        let cache = init_cache_if_needed();
        let mut cache_guard = cache.lock().unwrap();
        cache_guard.data = history;
        cache_guard.last_mtime = std::fs::metadata(
            &fs_manager::get_history_path(&app_handle).map_err(|e| e.to_string())?
        ).and_then(|m| m.modified()).ok();
        Ok(())
    } else {
        Err(format!("Item with ID '{}' not found", id))
    }
}

#[tauri::command]
fn update_favorite_status(
    app_handle: AppHandle,
    id: String,
    // å…¼å®¹å‰ç«¯ä¼ å‚ï¼šåŒæ—¶æ”¯æŒ snake_case ä¸ camelCase
    #[allow(non_snake_case)]
    is_favorite: Option<bool>,
    #[allow(non_snake_case)]
    isFavorite: Option<bool>,
) -> Result<(), String> {
    let is_favorite = is_favorite.or(isFavorite).ok_or_else(|| "missing is_favorite/isFavorite".to_string())?;
    let mut history = fs_manager::read_history(&app_handle).map_err(|e| e.to_string())?;
    if let Some(item) = history.iter_mut().find(|item| item.id == id) {
        item.is_favorite = is_favorite;
        fs_manager::write_history(&app_handle, &history).map_err(|e| e.to_string())?;
        let cache = init_cache_if_needed();
        let mut cache_guard = cache.lock().unwrap();
        cache_guard.data = history;
        cache_guard.last_mtime = std::fs::metadata(
            &fs_manager::get_history_path(&app_handle).map_err(|e| e.to_string())?
        ).and_then(|m| m.modified()).ok();
        Ok(())
    } else {
        Err(format!("Item with ID '{}' not found", id))
    }
}

#[tauri::command]
fn get_config(app_handle: AppHandle) -> Result<Config, String> {
    fs_manager::read_config(&app_handle).map_err(|e| e.to_string())
}

#[tauri::command]
fn save_config(app_handle: AppHandle, config: Config) -> Result<(), String> {
    fs_manager::write_config(&app_handle, &config).map_err(|e| e.to_string())
}

#[tauri::command]
fn register_global_shortcut(app_handle: AppHandle, shortcut: String) -> Result<(), String> {
    // å…ˆå–æ¶ˆæ³¨å†Œæ‰€æœ‰ç°æœ‰çš„å¿«æ·é”®
    app_handle.global_shortcut_manager().unregister_all().map_err(|e| e.to_string())?;

    // æ³¨å†Œæ–°çš„å¿«æ·é”®
    let app_handle_for_shortcut = app_handle.clone();
    app_handle.global_shortcut_manager().register(&shortcut, move || {
        let app_handle = app_handle_for_shortcut.clone();
        tauri::async_runtime::spawn(async move {
            if let Err(_e) = capture::open_overlays_for_all_displays(app_handle).await {
                #[cfg(debug_assertions)]
                eprintln!("Failed to open overlays from shortcut: {}", _e);
            }
        });
    }).map_err(|e| e.to_string())?;

    Ok(())
}

#[tauri::command]
async fn get_confidence_score(
    app_handle: AppHandle,
    latex: String,
) -> Result<u8, String> {
    let config = fs_manager::read_config(&app_handle).map_err(|e| e.to_string())?;
    let client = ApiClient::new(config.to_llm_config());
    let verification_prompt = prompts::get_verification_prompt(&config.language);
    let verification_result = client
        .get_verification_result(&verification_prompt, &latex)
        .await
        .map_err(|e| e.to_string())?;
    Ok(verification_result.confidence_score)
}

#[tauri::command]
async fn retry_analysis_phase(
    app_handle: AppHandle,
    image_base64: String,
) -> Result<(String, crate::data_models::Analysis), String> {
    let config = fs_manager::read_config(&app_handle).map_err(|e| e.to_string())?;
    let client = ApiClient::new(config.to_llm_config());
    let analysis_prompt = if !config.analysis_prompt.is_empty() {
        prompts::get_analysis_prompt(&config.language)
    } else {
        config.custom_prompt.clone()
    };

    let result = client
        .generate_analysis(&analysis_prompt, &image_base64)
        .await
        .map_err(|e| e.to_string())?;

    Ok(result)
}

#[tauri::command]
async fn retry_verification_phase(
    app_handle: AppHandle,
    latex: String,
    image_base64: String,
) -> Result<(crate::data_models::VerificationResult, Option<crate::data_models::Verification>), String> {
    let config = fs_manager::read_config(&app_handle).map_err(|e| e.to_string())?;
    let client = ApiClient::new(config.to_llm_config());
    let verification_prompt = prompts::get_verification_prompt(&config.language);

    match client.verify_latex_against_image(&latex, &image_base64, &config.language).await {
        Ok(v) => {
            let vr = compute_verification_result_from_struct(&v);
            Ok((vr, Some(v)))
        }
        Err(_) => {
            let fallback = client
                .get_verification_result_with_image(&verification_prompt, &latex, &image_base64)
                .await
                .unwrap_or(crate::data_models::VerificationResult { confidence_score: 0, verification_report: "éªŒè¯å¤±è´¥".to_string() });
            Ok((fallback, None))
        }
    }
}

fn main() {
    tauri::Builder::default()
        .setup(|app| {
            // è¯»å–é…ç½®å¹¶åº”ç”¨çª—å£å¤§å°/ä½ç½®
            let app_handle = app.handle();
            let cfg = fs_manager::read_config(&app_handle).unwrap_or_default();

            // æ³¨å†Œå…¨å±€å¿«æ·é”®
            let shortcut = cfg.screenshot_shortcut.clone();
            let app_handle_for_shortcut = app_handle.clone();
            if let Err(_e) = app.global_shortcut_manager().register(&shortcut, move || {
                let app_handle = app_handle_for_shortcut.clone();
                tauri::async_runtime::spawn(async move {
                    if let Err(e) = capture::open_overlays_for_all_displays(app_handle).await {
                        eprintln!("Failed to open overlays from shortcut: {}", e);
                    }
                });
            }) {
                #[cfg(debug_assertions)]
                eprintln!("Failed to register global shortcut '{}': {}", shortcut, _e);
            }
            if let Some(win) = app.get_window("main") {
                // è®¾ç½®çª—å£å›¾æ ‡ä¸ºè‡ªå®šä¹‰ ICOï¼ˆWindows ä»»åŠ¡æ ä¸æ ‡é¢˜æ å›¾æ ‡ï¼‰
                // è®¾ç½®çª—å£å›¾æ ‡ï¼ˆICO/PNG ç”± tauri-icon ç‰¹æ€§æ”¯æŒï¼‰
                // ä¼˜å…ˆä½¿ç”¨é«˜è´¨é‡ PNG ä½œä¸ºçª—å£å›¾æ ‡ï¼Œé¿å… ICO åœ¨æŸäº›ç¯å¢ƒæ¸²æŸ“å¼‚å¸¸
                if let Some(png_path) = app.path_resolver().resolve_resource("icons/icon-256.png") {
                    let _ = win.set_icon(tauri::Icon::File(png_path));
                } else if let Some(ico_path) = app.path_resolver().resolve_resource("icons/icon.ico") {
                    let _ = win.set_icon(tauri::Icon::File(ico_path));
                }
                // è®¾ç½®å°ºå¯¸
                use tauri::PhysicalSize;
                let _ = win.set_size(PhysicalSize::new(cfg.window_width, cfg.window_height));
                // è®¾ç½®ä½ç½®ï¼ˆå¯é€‰ï¼‰
                if let (Some(x), Some(y)) = (cfg.window_x, cfg.window_y) {
                    use tauri::PhysicalPosition;
                    let _ = win.set_position(PhysicalPosition::new(x, y));
                }
            }

            // ç›‘å¬å…³é—­æ—¶ä¿å­˜çª—å£ä½ç½®ä¸å°ºå¯¸
            if let Some(win) = app.get_window("main") {
                let app_handle_clone = app_handle.clone();
                let win_clone = win.clone();
                win.on_window_event(move |event| {
                    if let tauri::WindowEvent::CloseRequested { .. } = event {
                        // è¯»å–å½“å‰é…ç½®ï¼Œå†™å›çª—å£çŠ¶æ€ï¼ˆä»…åœ¨ remember_window_state ä¸º true æ—¶ï¼‰
                        if let Ok(mut cfg) = fs_manager::read_config(&app_handle_clone) {
                            if cfg.remember_window_state {
                                if let Ok(size) = win_clone.inner_size() {
                                    cfg.window_width = size.width;
                                    cfg.window_height = size.height;
                                }
                                if let Ok(pos) = win_clone.outer_position() {
                                    cfg.window_x = Some(pos.x);
                                    cfg.window_y = Some(pos.y);
                                }
                                let _ = fs_manager::write_config(&app_handle_clone, &cfg);
                            }
                        }
                    }
                });
            }

            Ok(())
        })
        .invoke_handler(tauri::generate_handler![
            test_connection,
            open_config_dir,
            recognize_from_screenshot,
            recognize_from_file,
            recognize_from_clipboard,
            recognize_from_image_base64,
            get_history,
            save_to_history,
            delete_history_item,
            update_favorite_status,
            update_history_title,
            get_config,
            save_config,
            register_global_shortcut,
            get_confidence_score,
            copy_image_to_clipboard,
            read_image_as_data_url,
            get_default_prompts,
            get_full_prompts_with_language,
            get_prompt_parts,
            retry_analysis_phase,
            retry_verification_phase,
            capture::open_overlays_for_all_displays,
            capture::complete_capture,
            capture::close_all_overlays,
            capture::start_recognition_from_region_capture
        ])
        .run(tauri::generate_context!())
        .expect("error while running tauri application");
}
